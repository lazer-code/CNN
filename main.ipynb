{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Installations"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:01:40.434078Z",
     "start_time": "2025-03-13T08:01:40.424556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "conda create -n CUDA_ENV python=3.10\n",
    "conda activate CUDA_ENV\n",
    "conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\n",
    "python -m pip install \"tensorflow==2.10\"\n",
    "conda install \"numpy<2\"\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nconda create -n CUDA_ENV python=3.10\\nconda activate CUDA_ENV\\nconda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0\\npython -m pip install \"tensorflow==2.10\"\\nconda install \"numpy<2\"\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:01:43.145489Z",
     "start_time": "2025-03-13T08:01:40.445157Z"
    }
   },
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling GPU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:01:43.304137Z",
     "start_time": "2025-03-13T08:01:43.254954Z"
    }
   },
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10240)])\n",
    "\n",
    "    print(tf.config.experimental.get_device_details(gpus[0])['device_name'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting database"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:01:43.336109Z",
     "start_time": "2025-03-13T08:01:43.321159Z"
    }
   },
   "source": [
    "model_path = \"All-Animals.keras\"\n",
    "model_exists = os.path.exists(model_path)\n",
    "\n",
    "retrain = False\n",
    "dataset = \"All-Animals/\"\n",
    "train = f\"{dataset}Train\"\n",
    "valid = f\"{dataset}Valid\"\n",
    "test = f\"{dataset}Test\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:02:37.158475Z",
     "start_time": "2025-03-13T08:01:43.352818Z"
    }
   },
   "source": [
    "augmented_root = f\"{dataset}Augmented\"\n",
    "recreate = not os.path.isdir(augmented_root)\n",
    "\n",
    "if recreate:\n",
    "    for path in [train, valid, test]:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for index, file in enumerate(files):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg')):\n",
    "                    old_path = os.path.join(root, file)\n",
    "                    with Image.open(old_path) as img:\n",
    "                        img = img.convert(\"RGB\")\n",
    "                        new_filename = f\"{os.path.basename(root)}_{index + 1}.jpeg\"\n",
    "                        new_path = os.path.join(root, new_filename)\n",
    "                        img.save(new_path, 'JPEG')\n",
    "                    os.remove(old_path)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting pictures"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T10:04:52.065213Z",
     "start_time": "2025-03-13T08:02:37.176169Z"
    }
   },
   "source": [
    "if recreate:\n",
    "    for root, dirs, files in os.walk(train):\n",
    "        parent_folder = os.path.basename(root)\n",
    "        augmented_folder = os.path.join(augmented_root, parent_folder)\n",
    "        os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file.lower())\n",
    "            if '_aug_' not in path:\n",
    "                img = np.array(Image.open(path))\n",
    "                datagen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.3, horizontal_flip=True, brightness_range=[0.8, 1.2])\n",
    "                augmented_images = [next(datagen.flow(np.expand_dims(img, 0), batch_size=1))[0] for _ in range(100)]\n",
    "                to = 4 if path.endswith(\".jpg\") else 5 if path.endswith(\".jpeg\") else 1\n",
    "                for i, aug_img in enumerate(augmented_images):\n",
    "                    aug_img_path = os.path.join(augmented_folder, f\"{file[:-to]}_aug_{i+1}.jpeg\")\n",
    "                    Image.fromarray(aug_img.astype(\"uint8\")).save(aug_img_path)\n",
    "\n",
    "train = augmented_root"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T07:41:45.635792300Z",
     "start_time": "2025-03-13T07:00:05.137534Z"
    }
   },
   "source": [
    "if recreate:\n",
    "    img_size = (256, 256)\n",
    "    batch_size = 32\n",
    "\n",
    "    train_ds = image_dataset_from_directory(train, image_size=img_size, batch_size=batch_size)\n",
    "    val_ds = image_dataset_from_directory(valid, image_size=img_size, batch_size=batch_size)\n",
    "    test_ds = image_dataset_from_directory(test, image_size=img_size, batch_size=batch_size)\n",
    "\n",
    "    class_names = train_ds.class_names\n",
    "    print(class_names)"
   ],
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory Sea-Animal/Augmented",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m img_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m)\n\u001B[0;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m\n\u001B[1;32m----> 5\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mimage_dataset_from_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimg_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m val_ds \u001B[38;5;241m=\u001B[39m image_dataset_from_directory(valid, image_size\u001B[38;5;241m=\u001B[39mimg_size, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m      7\u001B[0m test_ds \u001B[38;5;241m=\u001B[39m image_dataset_from_directory(test, image_size\u001B[38;5;241m=\u001B[39mimg_size, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n",
      "File \u001B[1;32m~\\.conda\\envs\\CUDA_ENV\\lib\\site-packages\\keras\\utils\\image_dataset.py:207\u001B[0m, in \u001B[0;36mimage_dataset_from_directory\u001B[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m seed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     seed \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m1e6\u001B[39m)\n\u001B[1;32m--> 207\u001B[0m image_paths, labels, class_names \u001B[38;5;241m=\u001B[39m \u001B[43mdataset_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_directory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43mformats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mALLOWLIST_FORMATS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_links\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_links\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m label_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(class_names) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWhen passing `label_mode=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`, there must be exactly 2 \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_names. Received: class_names=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclass_names\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\CUDA_ENV\\lib\\site-packages\\keras\\utils\\dataset_utils.py:524\u001B[0m, in \u001B[0;36mindex_directory\u001B[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001B[0m\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    523\u001B[0m     subdirs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 524\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subdir \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mjoin(directory, subdir)):\n\u001B[0;32m    526\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m subdir\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\CUDA_ENV\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:766\u001B[0m, in \u001B[0;36mlist_directory_v2\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    751\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001B[39;00m\n\u001B[0;32m    752\u001B[0m \n\u001B[0;32m    753\u001B[0m \u001B[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001B[39;00m\n\u001B[0;32m    764\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    765\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_directory(path):\n\u001B[1;32m--> 766\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mNotFoundError(\n\u001B[0;32m    767\u001B[0m       node_def\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    768\u001B[0m       op\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    769\u001B[0m       message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find directory \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(path))\n\u001B[0;32m    771\u001B[0m \u001B[38;5;66;03m# Convert each element to string, since the return values of the\u001B[39;00m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001B[39;00m\n\u001B[0;32m    773\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    774\u001B[0m     compat\u001B[38;5;241m.\u001B[39mas_str_any(filename)\n\u001B[0;32m    775\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m _pywrap_file_io\u001B[38;5;241m.\u001B[39mGetChildren(compat\u001B[38;5;241m.\u001B[39mpath_to_bytes(path))\n\u001B[0;32m    776\u001B[0m ]\n",
      "\u001B[1;31mNotFoundError\u001B[0m: Could not find directory Sea-Animal/Augmented"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T07:41:45.663351300Z",
     "start_time": "2025-03-12T21:22:48.760932Z"
    }
   },
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    if not retrain:\n",
    "        model = keras.Sequential([\n",
    "            layers.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(len(class_names), activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    epochs = 20\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "    model.save(model_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13397/13397 [==============================] - 748s 53ms/step - loss: 1.1874 - accuracy: 0.6127 - val_loss: 2.2715 - val_accuracy: 0.5390\n",
      "Epoch 2/20\n",
      "13397/13397 [==============================] - 711s 53ms/step - loss: 0.5772 - accuracy: 0.8093 - val_loss: 2.1253 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "13397/13397 [==============================] - 710s 53ms/step - loss: 0.3338 - accuracy: 0.8891 - val_loss: 3.0515 - val_accuracy: 0.6596\n",
      "Epoch 4/20\n",
      "13397/13397 [==============================] - 709s 53ms/step - loss: 0.2335 - accuracy: 0.9240 - val_loss: 3.7774 - val_accuracy: 0.6383\n",
      "Epoch 5/20\n",
      "13397/13397 [==============================] - 709s 53ms/step - loss: 0.1854 - accuracy: 0.9405 - val_loss: 3.9495 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "13397/13397 [==============================] - 708s 53ms/step - loss: 0.1651 - accuracy: 0.9486 - val_loss: 4.1759 - val_accuracy: 0.6596\n",
      "Epoch 7/20\n",
      "13397/13397 [==============================] - 708s 53ms/step - loss: 0.1477 - accuracy: 0.9557 - val_loss: 5.7756 - val_accuracy: 0.6170\n",
      "Epoch 8/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1378 - accuracy: 0.9595 - val_loss: 4.6945 - val_accuracy: 0.6738\n",
      "Epoch 9/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1314 - accuracy: 0.9626 - val_loss: 7.3145 - val_accuracy: 0.6454\n",
      "Epoch 10/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1243 - accuracy: 0.9651 - val_loss: 6.5147 - val_accuracy: 0.6454\n",
      "Epoch 11/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1236 - accuracy: 0.9667 - val_loss: 6.2754 - val_accuracy: 0.6312\n",
      "Epoch 12/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1195 - accuracy: 0.9689 - val_loss: 7.8239 - val_accuracy: 0.5887\n",
      "Epoch 13/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1164 - accuracy: 0.9700 - val_loss: 8.7186 - val_accuracy: 0.6241\n",
      "Epoch 14/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1145 - accuracy: 0.9715 - val_loss: 7.8966 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1121 - accuracy: 0.9725 - val_loss: 7.0575 - val_accuracy: 0.6454\n",
      "Epoch 16/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1112 - accuracy: 0.9738 - val_loss: 10.8726 - val_accuracy: 0.6099\n",
      "Epoch 17/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1111 - accuracy: 0.9745 - val_loss: 9.5635 - val_accuracy: 0.6454\n",
      "Epoch 18/20\n",
      "13397/13397 [==============================] - 707s 53ms/step - loss: 0.1144 - accuracy: 0.9752 - val_loss: 10.9096 - val_accuracy: 0.6596\n",
      "Epoch 19/20\n",
      "13397/13397 [==============================] - 706s 53ms/step - loss: 0.1159 - accuracy: 0.9753 - val_loss: 10.0978 - val_accuracy: 0.6738\n",
      "Epoch 20/20\n",
      "13397/13397 [==============================] - 706s 53ms/step - loss: 0.1134 - accuracy: 0.9765 - val_loss: 10.1468 - val_accuracy: 0.6312\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T07:41:45.665344900Z",
     "start_time": "2025-03-13T06:20:49.403949Z"
    }
   },
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "predictions = model.predict(test_ds)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\n",
    "\n",
    "misclassified_indices = np.where(pred_labels != true_labels)[0]\n",
    "\n",
    "misclassified_data = [(true_labels[idx], pred_labels[idx]) for idx in misclassified_indices[:10]]\n",
    "\n",
    "print(misclassified_data)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1478 - accuracy: 0.6312\n",
      "Test Accuracy: 0.6312\n",
      "7/7 [==============================] - 0s 14ms/step\n",
      "[(6, 4), (4, 12), (2, 12), (10, 12), (6, 3), (10, 8), (6, 12), (8, 10), (6, 10), (6, 9)]\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
