{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7770af9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128f4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pandas as pd, kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0231330",
   "metadata": {},
   "source": [
    "### Downloading The Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6cc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/a2015003713/militaryaircraftdetectiondataset?dataset_version_number=88...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.98G/9.98G [06:10<00:00, 28.9MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aircrafts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"a2015003713/militaryaircraftdetectiondataset\")\n",
    "shutil.move(path, \"Aircrafts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc82186",
   "metadata": {},
   "source": [
    "### Removing The Unused Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ed4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"Aircrafts/annotated_samples\")\n",
    "shutil.rmtree(\"Aircrafts/crop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553758a7",
   "metadata": {},
   "source": [
    "### Pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'Aircrafts/labels_with_split.csv'\n",
    "img_dir = 'Aircrafts/dataset'\n",
    "output_dir = 'Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c00a2a",
   "metadata": {},
   "source": [
    "### Creating The Necessary Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train/images', 'validation': 'valid/images', 'test': 'test/images'}\n",
    "for split_path in splits.values():\n",
    "    os.makedirs(f'{output_dir}/{split_path}', exist_ok=True)\n",
    "    os.makedirs(f'{output_dir}/{split_path.replace(\"images\", \"labels\")}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418042c",
   "metadata": {},
   "source": [
    "### Extracting The Data From The CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "class_names = sorted(df['class'].unique())\n",
    "class_to_id = {name: i for i, name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b470129",
   "metadata": {},
   "source": [
    "### Converting The Data To YOLO's Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbede77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo_format(row):\n",
    "    x_center = (row['xmin'] + row['xmax']) / 2 / row['width']\n",
    "    y_center = (row['ymin'] + row['ymax']) / 2 / row['height']\n",
    "    box_width = (row['xmax'] - row['xmin']) / row['width']\n",
    "    box_height = (row['ymax'] - row['ymin']) / row['height']\n",
    "    cls_id = class_to_id[row['class']]\n",
    "    return f\"{cls_id} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\"\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    split_df = df[df['split'] == split]\n",
    "    for _, row in split_df.iterrows():\n",
    "        img_filename = row['filename'] + '.jpg'\n",
    "        img_src = os.path.join(img_dir, img_filename)\n",
    "        img_dst = os.path.join(output_dir, splits[split], img_filename)\n",
    "        label_dst = os.path.join(output_dir, splits[split].replace(\"images\", \"labels\"), row['filename'] + '.txt')\n",
    "        shutil.copy(img_src, img_dst)\n",
    "        with open(label_dst, 'w') as f:\n",
    "            annotations = split_df[split_df['filename'] == row['filename']]\n",
    "            for _, annotation in annotations.iterrows():\n",
    "                f.write(convert_to_yolo_format(annotation) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49edfc1",
   "metadata": {},
   "source": [
    "### Creating The YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_dir}/data.yaml', 'w') as f:\n",
    "    f.write(f\"train: {output_dir}/train/images\\n\")\n",
    "    f.write(f\"val: {output_dir}/valid/images\\n\")\n",
    "    f.write(f\"test: {output_dir}/test/images\\n\\n\")\n",
    "    f.write(f\"nc: {len(class_names)}\\n\")\n",
    "    f.write(f\"names: {class_names}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
